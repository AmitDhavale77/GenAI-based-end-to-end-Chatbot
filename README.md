# End-to-end-Chatbot-using-Claude-3 

## Project Overview

This project demonstrates how to build an end-to-end chatbot using the **Claude 3 sonnet** model for natural language processing. The chatbot integrates **Pinecone**, a vector database, for efficient document retrieval and **Flask** to create a web interface. The chatbot answers questions based on a pre-loaded medical dataset using embeddings generated by **Hugging Face**. It leverages **LangChain** and **CTransformers** to handle the retrieval and response generation efficiently.

## Features

- **Chat Interface**: A simple web interface where users can interact with the chatbot by typing messages.
- **Pinecone Integration**: Stores and retrieves the document embeddings using Pinecone for fast similarity search.
- **Claude 3 sonnet Integration**: Uses the Claude 3 model for generating natural language responses based on the userâ€™s query.
- **Flask Web Application**: The app is built using Flask, providing an easy-to-use front-end for users to interact with the chatbot.

## How It Works

### 1. **User Input**
The user submits a query through the web interface (`chat.html`). The input message is then captured by the Flask app and passed to the chatbot for processing.

### 2. **Document Retrieval**
The chatbot uses **Pinecone** as a vector store to retrieve relevant documents based on the query. Embeddings for the documents are generated using the **Hugging Face embeddings** and stored in Pinecone for efficient retrieval.

### 3. **Response Generation**
Once relevant documents are retrieved, the **Claude 3 model** (via **CTransformers**) is used to generate a response. The model takes the retrieved context and the query to produce a coherent answer.

### 4. **Displaying the Result**
The generated response is displayed on the web interface for the user to view. The application also displays the source documents from which the answer was generated, ensuring transparency in the response generation process.

